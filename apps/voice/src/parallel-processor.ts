import path from 'path';
import { VoiceTask } from './generator.js';
import { TranslateConfig, CharacterVoiceConfig } from './config.js';
import { GPTSoVITSAPI } from './request.js';
import { TranslateService } from './translate/index.js';
import { getMaxTranslator } from '@webgal-tools/config';
import { logger } from '@webgal-tools/logger';
import { ModelScanner } from './model-scanner.js';
import { ScannedModelFiles, EmotionRecognitionResult } from '@webgal-tools/config';

interface TranslateTask {
  id: string;
  character: string;
  originalText: string;
  targetLanguage: string;
  audioFileName: string;
  context?: string;
  characterConfig?: CharacterVoiceConfig;
  isAutoMode?: boolean; // æ–°å¢ï¼šæ ‡è¯†æ˜¯å¦ä¸ºè‡ªåŠ¨æ¨¡å¼
  gptSovitsPath?: string; // æ–°å¢ï¼šGPT-SoVITSè·¯å¾„
}

interface TranslateResult {
  id: string;
  character: string;
  originalText: string;
  translatedText: string;
  audioFileName: string;
  success: boolean;
  error?: string;
  isAutoMode?: boolean; // æ–°å¢ï¼šæ ‡è¯†æ˜¯å¦ä¸ºè‡ªåŠ¨æ¨¡å¼
  emotionResult?: EmotionRecognitionResult; // æ–°å¢ï¼šæƒ…ç»ªè¯†åˆ«ç»“æœ
}

interface VoiceSynthesisTask extends VoiceTask {
  id: string;
  characterConfig: CharacterVoiceConfig;
}

/**
 * å¹¶å‘æ§åˆ¶å™¨ - åŸºäºPromiseè€Œéå¤šè¿›ç¨‹
 */
export class ParallelProcessor {
  private api: GPTSoVITSAPI;
  private audioOutputDir: string;
  private translateService: TranslateService;
  private gptSovitsPath: string; // æ–°å¢ï¼šGPT-SoVITSè·¯å¾„

  // çŠ¶æ€è·Ÿè¸ª
  private totalTasks = 0;
  private completedTranslateCount = 0;
  private completedVoiceCount = 0;
  private completedVoiceTasks: VoiceTask[] = [];

  // è¯­éŸ³åˆæˆé˜Ÿåˆ—å’ŒçŠ¶æ€
  private voiceQueue: TranslateResult[] = [];
  private isVoiceSynthesizing = false;
  private currentCharacter: string | null = null;

  // å¹¶å‘æ§åˆ¶
  private maxConcurrency: number;
  private activeTranslations = 0;

  // å›è°ƒå‡½æ•°
  private onTranslateProgress?: (completed: number, total: number, result: TranslateResult) => void;
  private onVoiceProgress?: (completed: number, total: number, result: VoiceTask) => void;
  private onError?: (error: Error, task: TranslateTask | VoiceTask) => void;

  constructor(api: GPTSoVITSAPI, audioOutputDir: string, gptSovitsPath?: string) {
    this.api = api;
    this.audioOutputDir = audioOutputDir;
    this.gptSovitsPath = gptSovitsPath || '';
    this.translateService = new TranslateService();
    // ä»é…ç½®è·å–æœ€å¤§å¹¶å‘æ•°
    this.maxConcurrency = getMaxTranslator();
    logger.info(`ğŸ”§ æœ€å¤§å¹¶å‘æ•°: ${this.maxConcurrency}`);
  }

  /**
   * è®¾ç½®è¿›åº¦å›è°ƒå‡½æ•°
   */
  setCallbacks(callbacks: {
    onTranslateProgress?: (completed: number, total: number, result: TranslateResult) => void;
    onVoiceProgress?: (completed: number, total: number, result: VoiceTask) => void;
    onError?: (error: Error, task: TranslateTask | VoiceTask) => void;
  }): void {
    this.onTranslateProgress = callbacks.onTranslateProgress;
    this.onVoiceProgress = callbacks.onVoiceProgress;
    this.onError = callbacks.onError;
  }

  /**
   * é™åˆ¶å¹¶å‘æ‰§è¡Œçš„Promiseå·¥å…·å‡½æ•°
   */
  private async limitConcurrency<T>(
    tasks: (() => Promise<T>)[],
    limit: number,
    onProgress?: (completed: number, total: number, result: T) => void
  ): Promise<T[]> {
    const results: T[] = [];
    const executing: Promise<void>[] = [];
    let completed = 0;

    for (const task of tasks) {
      const promise = task().then((result) => {
        completed++;
        results.push(result);
        if (onProgress) {
          onProgress(completed, tasks.length, result);
        }
      });

      executing.push(promise);

      if (executing.length >= limit) {
        await Promise.race(executing);
        executing.splice(executing.findIndex(p => 
          p === promise || (p as any)._isCompleted
        ), 1);
      }
    }

    await Promise.all(executing);
    return results;
  }

  /**
   * æ‰§è¡Œå•ä¸ªç¿»è¯‘ä»»åŠ¡
   */
  private async translateSingleTask(
    task: TranslateTask,
    config: TranslateConfig
  ): Promise<TranslateResult> {
    try {
      logger.info(`ğŸ”„ å¼€å§‹ç¿»è¯‘: ${task.character} - ${task.originalText.substring(0, 20)}...`);

      let translatedText: string;
      let emotionResult: EmotionRecognitionResult | undefined;

      if (task.isAutoMode && task.characterConfig && task.gptSovitsPath) {
        // è‡ªåŠ¨æ¨¡å¼ï¼šæ‰§è¡Œæƒ…ç»ªè¯†åˆ«å’Œæ¨¡å‹é€‰æ‹©
        logger.info(`ğŸ¤– [${task.character}] è‡ªåŠ¨æ¨¡å¼ - æ‰§è¡Œæƒ…ç»ªè¯†åˆ«å’Œæ¨¡å‹é€‰æ‹©...`);
        
        // æ„å»ºæ–‡ä»¶å¤¹è·¯å¾„
        const gptDir = path.resolve(task.gptSovitsPath, task.characterConfig.gpt);
        const sovitsDir = path.resolve(task.gptSovitsPath, task.characterConfig.sovits);
        const refAudioDir = task.characterConfig.ref_audio;

        // æ‰«ææ¨¡å‹æ–‡ä»¶
        const scannedFiles = ModelScanner.scanModelFiles(task.gptSovitsPath, gptDir, sovitsDir, refAudioDir);

        // æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ–‡ä»¶
        if (scannedFiles.gpt_files.length === 0) {
          throw new Error(`æœªæ‰¾åˆ°GPTæ¨¡å‹æ–‡ä»¶åœ¨: ${gptDir}`);
        }
        if (scannedFiles.sovits_files.length === 0) {
          throw new Error(`æœªæ‰¾åˆ°SoVITSæ¨¡å‹æ–‡ä»¶åœ¨: ${sovitsDir}`);
        }
        if (scannedFiles.ref_audio_files.length === 0) {
          throw new Error(`æœªæ‰¾åˆ°å‚è€ƒéŸ³é¢‘æ–‡ä»¶åœ¨: ${refAudioDir}`);
        }

        // æ‰§è¡Œæƒ…ç»ªè¯†åˆ«å’Œæ¨¡å‹é€‰æ‹©
        emotionResult = await this.translateService.selectModelAndTranslate(
          task.character,
          task.originalText,
          task.targetLanguage,
          scannedFiles,
          config,
          task.characterConfig,
          task.context
        );

        translatedText = emotionResult.translated_text;
        logger.info(`âœ… [${task.character}] è‡ªåŠ¨æ¨¡å¼ç¿»è¯‘å®Œæˆ - æƒ…ç»ª: ${emotionResult.emotion}`);
      } else {
        // æ­£å¸¸æ¨¡å¼ï¼šå¸¸è§„ç¿»è¯‘
        translatedText = await this.translateService.translate(
          task.character,
          task.originalText,
          task.targetLanguage,
          config,
          task.characterConfig,
          task.context
        );
      }

      const result: TranslateResult = {
        id: task.id,
        character: task.character,
        originalText: task.originalText,
        translatedText,
        audioFileName: task.audioFileName,
        success: true,
        isAutoMode: task.isAutoMode,
        emotionResult
      };

      logger.info(`âœ… ç¿»è¯‘å®Œæˆ: ${task.character} - ${translatedText.substring(0, 20)}...`);
      return result;

    } catch (error) {
      logger.error(`âŒ ç¿»è¯‘å¤±è´¥ ${task.character}:`, error);
      
      const result: TranslateResult = {
        id: task.id,
        character: task.character,
        originalText: task.originalText,
        translatedText: task.originalText, // å¤±è´¥æ—¶ä½¿ç”¨åŸæ–‡
        audioFileName: task.audioFileName,
        success: false,
        error: error instanceof Error ? error.message : String(error),
        isAutoMode: task.isAutoMode
      };

      if (this.onError) {
        this.onError(error instanceof Error ? error : new Error(String(error)), task);
      }

      return result;
    }
  }

  /**
   * å¹¶å‘æ‰§è¡Œç¿»è¯‘ä»»åŠ¡
   */
  private async translateTasks(
    tasks: TranslateTask[],
    config: TranslateConfig
  ): Promise<TranslateResult[]> {
    if (tasks.length === 0) {
      return [];
    }

    logger.info(`ğŸš€ å¼€å§‹å¹¶å‘ç¿»è¯‘ ${tasks.length} ä¸ªä»»åŠ¡ï¼Œæœ€å¤§å¹¶å‘æ•°: ${this.maxConcurrency}`);

    const taskFunctions = tasks.map(task => 
      () => this.translateSingleTask(task, config)
    );

    return this.limitConcurrency(
      taskFunctions,
      this.maxConcurrency,
      (completed, total, result) => {
        this.completedTranslateCount = completed;
        if (this.onTranslateProgress) {
          this.onTranslateProgress(completed, total, result);
        }
        // å°†ç¿»è¯‘å®Œæˆçš„ä»»åŠ¡åŠ å…¥è¯­éŸ³åˆæˆé˜Ÿåˆ—
        this.enqueueVoiceSynthesis(result);
      }
    );
  }

  /**
   * å°†ç¿»è¯‘ç»“æœåŠ å…¥è¯­éŸ³åˆæˆé˜Ÿåˆ—
   */
  private enqueueVoiceSynthesis(translateResult: TranslateResult): void {
    this.voiceQueue.push(translateResult);
    logger.info(`ğŸ“‹ åŠ å…¥è¯­éŸ³åˆæˆé˜Ÿåˆ—: ${translateResult.character} (é˜Ÿåˆ—é•¿åº¦: ${this.voiceQueue.length})`);

    // è§¦å‘è¯­éŸ³åˆæˆå¤„ç†
    this.processVoiceQueue();
  }

  /**
   * å¤„ç†è¯­éŸ³åˆæˆé˜Ÿåˆ—ï¼ˆä¿æŒå•çº¿ç¨‹ä»¥é¿å…æ¨¡å‹åˆ‡æ¢å†²çªï¼‰
   */
  private async processVoiceQueue(): Promise<void> {
    if (this.isVoiceSynthesizing || this.voiceQueue.length === 0) {
      return;
    }

    this.isVoiceSynthesizing = true;

    while (this.voiceQueue.length > 0) {
      const translateResult = this.voiceQueue.shift()!;

      // ä¼˜å…ˆå¤„ç†åŒä¸€è§’è‰²çš„ä»»åŠ¡
      if (this.currentCharacter && this.currentCharacter !== translateResult.character) {
        const sameCharacterIndex = this.voiceQueue.findIndex(task => task.character === this.currentCharacter);
        if (sameCharacterIndex !== -1) {
          this.voiceQueue.unshift(translateResult);
          const sameCharacterTask = this.voiceQueue.splice(sameCharacterIndex + 1, 1)[0];
          await this.synthesizeVoice(sameCharacterTask);
          continue;
        }
      }

      await this.synthesizeVoice(translateResult);
    }

    this.isVoiceSynthesizing = false;
  }

  /**
   * æ‰§è¡Œè¯­éŸ³åˆæˆ
   */
  private async synthesizeVoice(translateResult: TranslateResult): Promise<void> {
    try {
      logger.info(`ğŸµ å¼€å§‹è¯­éŸ³åˆæˆ: ${translateResult.character} (é˜Ÿåˆ—å‰©ä½™: ${this.voiceQueue.length})`);

      // æ‰¾åˆ°å¯¹åº”çš„è§’è‰²é…ç½®
      const characterConfig = this.characterConfigs?.get(translateResult.character);
      if (!characterConfig) {
        throw new Error(`æœªæ‰¾åˆ°è§’è‰²é…ç½®: ${translateResult.character}`);
      }

      let finalCharacterConfig: CharacterVoiceConfig;
      let refAudioPath: string;
      let refText: string;

      if (translateResult.isAutoMode && translateResult.emotionResult) {
        // è‡ªåŠ¨æ¨¡å¼ï¼šä½¿ç”¨æƒ…ç»ªè¯†åˆ«ç»“æœ
        const emotionResult = translateResult.emotionResult;
        
        // åˆ›å»ºä¸´æ—¶çš„è§’è‰²é…ç½®
        finalCharacterConfig = {
          ...characterConfig,
          gpt: emotionResult.gpt,
          sovits: emotionResult.sovits,
          ref_audio: emotionResult.ref_audio,
          ref_text: ModelScanner.extractRefTextFromAudioFileName(emotionResult.ref_audio)
        };

        refAudioPath = emotionResult.ref_audio;
        refText = ModelScanner.extractRefTextFromAudioFileName(emotionResult.ref_audio);
        
        logger.info(`ğŸ¤– [${translateResult.character}] è‡ªåŠ¨æ¨¡å¼ - ä½¿ç”¨æƒ…ç»ª: ${emotionResult.emotion}`);
      } else {
        // æ­£å¸¸æ¨¡å¼ï¼šä½¿ç”¨åŸé…ç½®
        finalCharacterConfig = characterConfig;
        refAudioPath = characterConfig.ref_audio;
        refText = characterConfig.ref_text;
      }

      // æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ‡æ¢è§’è‰²æ¨¡å‹
      const modelKey = `${finalCharacterConfig.gpt}_${finalCharacterConfig.sovits}`;
      const currentModelKey = this.currentCharacter ? `${this.characterConfigs?.get(this.currentCharacter)?.gpt}_${this.characterConfigs?.get(this.currentCharacter)?.sovits}` : null;

      if (currentModelKey !== modelKey) {
        logger.info(`ğŸ”„ åˆ‡æ¢åˆ°è§’è‰²æ¨¡å‹: ${translateResult.character} (${finalCharacterConfig.gpt}/${finalCharacterConfig.sovits})`);

        await this.api.setGptModel(finalCharacterConfig.gpt);
        await this.api.setSovitsModel(
          finalCharacterConfig.sovits,
          finalCharacterConfig.inferrence_config?.prompt_language || 'ä¸­æ–‡',
          finalCharacterConfig.inferrence_config?.text_language || 'ä¸­æ–‡'
        );

        this.currentCharacter = translateResult.character;
      }

      // ç”Ÿæˆè¯­éŸ³
      const outputPath = await this.api.generateVoice(
        refAudioPath,
        refText,
        translateResult.translatedText,
        finalCharacterConfig.inferrence_config || {}
      );

      // ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
      const finalAudioPath = path.join(this.audioOutputDir, translateResult.audioFileName);
      await this.api.downloadAudio(outputPath, finalAudioPath);

      // åˆ›å»ºå®Œæˆçš„ä»»åŠ¡
      const completedTask: VoiceTask = {
        character: translateResult.character,
        originalText: translateResult.originalText,
        targetText: translateResult.translatedText,
        audioFileName: translateResult.audioFileName
      };

      this.completedVoiceTasks.push(completedTask);
      this.completedVoiceCount++;

      logger.info(`âœ… è¯­éŸ³åˆæˆå®Œæˆ: ${translateResult.character} - ${translateResult.audioFileName}`);

      if (this.onVoiceProgress) {
        this.onVoiceProgress(this.completedVoiceCount, this.totalTasks, completedTask);
      }

    } catch (error) {
      logger.error(`âŒ è¯­éŸ³åˆæˆå¤±è´¥ ${translateResult.character}:`, error);
      this.completedVoiceCount++;

      if (this.onError) {
        const voiceTask: VoiceTask = {
          character: translateResult.character,
          originalText: translateResult.originalText,
          targetText: translateResult.translatedText,
          audioFileName: translateResult.audioFileName
        };
        this.onError(error instanceof Error ? error : new Error(String(error)), voiceTask);
      }
    }
  }

  // å­˜å‚¨è§’è‰²é…ç½®çš„å¼•ç”¨
  private characterConfigs?: Map<string, CharacterVoiceConfig>;

  /**
   * å¤„ç†ç¿»è¯‘å’Œè¯­éŸ³åˆæˆä»»åŠ¡ï¼ˆæ–°çš„åŸºäºPromiseçš„å®ç°ï¼‰
   */
  async processTasksParallel(
    voiceTasks: VoiceTask[],
    characterConfigs: Map<string, CharacterVoiceConfig>,
    translateConfig: TranslateConfig,
    contextMap: Map<string, string>,
    gptSovitsPath?: string // æ–°å¢ï¼šGPT-SoVITSè·¯å¾„å‚æ•°
  ): Promise<VoiceTask[]> {

    this.characterConfigs = characterConfigs;
    this.totalTasks = voiceTasks.length;
    this.completedTranslateCount = 0;
    this.completedVoiceCount = 0;
    this.completedVoiceTasks = [];
    this.voiceQueue = [];

    // æ›´æ–° gptSovitsPath å¦‚æœæä¾›äº†
    if (gptSovitsPath) {
      this.gptSovitsPath = gptSovitsPath;
    }

    if (this.totalTasks === 0) {
      return [];
    }

    logger.info(`ğŸš€ å¼€å§‹å¹¶è¡Œå¤„ç† ${this.totalTasks} ä¸ªä»»åŠ¡`);

    // å‡†å¤‡ç¿»è¯‘ä»»åŠ¡
    const translateTasks: TranslateTask[] = [];
    const noTranslateTasks: TranslateResult[] = [];

    for (const task of voiceTasks) {
      const characterConfig = characterConfigs.get(task.character);
      if (!characterConfig) {
        logger.error(`âŒ è§’è‰² ${task.character} æœªåœ¨é…ç½®ä¸­æ‰¾åˆ°`);
        continue;
      }

      const taskId = `${task.character}_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
      const isAutoMode = characterConfig.auto === true;

      const translateTarget = characterConfig.translate_to;
      if (translateTarget || isAutoMode) {
        // éœ€è¦ç¿»è¯‘æˆ–è€…æ˜¯è‡ªåŠ¨æ¨¡å¼
        const taskKey = `${task.character}:${task.originalText}`;
        const context = contextMap.get(taskKey);

        const translateTask: TranslateTask = {
          id: taskId,
          character: task.character,
          originalText: task.originalText,
          targetLanguage: translateTarget || 'ä¸­æ–‡', // è‡ªåŠ¨æ¨¡å¼é»˜è®¤ä¸­æ–‡
          audioFileName: task.audioFileName,
          context,
          characterConfig,
          isAutoMode, // æ ‡è¯†æ˜¯å¦ä¸ºè‡ªåŠ¨æ¨¡å¼
          gptSovitsPath: this.gptSovitsPath
        };

        translateTasks.push(translateTask);
        
        if (isAutoMode) {
          logger.info(`ğŸ¤– åˆ›å»ºè‡ªåŠ¨æ¨¡å¼ä»»åŠ¡: ${task.character} - ${task.originalText.substring(0, 20)}...`);
        } else {
          logger.info(`ğŸ“ åˆ›å»ºç¿»è¯‘ä»»åŠ¡: ${task.character} - ${task.originalText.substring(0, 20)}...`);
        }
      } else {
        // ä¸éœ€è¦ç¿»è¯‘ï¼Œç›´æ¥ä½¿ç”¨åŸæ–‡
        const result: TranslateResult = {
          id: taskId,
          character: task.character,
          originalText: task.originalText,
          translatedText: task.originalText,
          audioFileName: task.audioFileName,
          success: true,
          isAutoMode: false
        };

        noTranslateTasks.push(result);
        logger.info(`âœ… æ— éœ€ç¿»è¯‘ä»»åŠ¡: ${task.character} - ${task.originalText.substring(0, 20)}...`);
      }
    }

    // å…ˆå°†ä¸éœ€è¦ç¿»è¯‘çš„ä»»åŠ¡åŠ å…¥è¯­éŸ³åˆæˆé˜Ÿåˆ—
    for (const result of noTranslateTasks) {
      this.enqueueVoiceSynthesis(result);
    }

    // å¹¶å‘æ‰§è¡Œç¿»è¯‘ä»»åŠ¡ï¼ˆåŒ…æ‹¬è‡ªåŠ¨æ¨¡å¼å’Œæ™®é€šæ¨¡å¼ï¼‰
    if (translateTasks.length > 0) {
      const autoModeCount = translateTasks.filter(t => t.isAutoMode).length;
      const normalModeCount = translateTasks.length - autoModeCount;
      
      logger.info(`ğŸ“Š å¼€å§‹å¹¶è¡Œå¤„ç†ç¿»è¯‘ä»»åŠ¡: è‡ªåŠ¨æ¨¡å¼ ${autoModeCount} ä¸ª, æ™®é€šæ¨¡å¼ ${normalModeCount} ä¸ª`);
      
      await this.translateTasks(translateTasks, translateConfig);
    }

    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    return new Promise((resolve) => {
      const checkCompletion = () => {
        if (this.completedVoiceCount >= this.totalTasks) {
          logger.info(`ğŸ‰ å¹¶è¡Œå¤„ç†å®Œæˆï¼æˆåŠŸå¤„ç† ${this.completedVoiceTasks.length}/${this.totalTasks} ä¸ªä»»åŠ¡`);
          resolve(this.completedVoiceTasks);
        } else {
          setTimeout(checkCompletion, 100);
        }
      };

      checkCompletion();
    });
  }

  /**
   * æ¸…ç†èµ„æº
   */
  cleanup(): void {
    // æ¸…ç†ç¿»è¯‘æœåŠ¡ç¼“å­˜
    this.translateService.clearCache();
    logger.info('ğŸ›‘ å¹¶è¡Œå¤„ç†å™¨èµ„æºå·²æ¸…ç†');
  }
} 