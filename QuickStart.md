本视频将分为以下章节

1. 工具安装和环境搭建
2. voice-ui界面介绍、配置详解
3. 开始第一个工作流：“静态角色配置”
4. 开始第二个工作流：“动态角色配置”
5. 语义化文件路径
6. 模型选择和优化
7. cli界面介绍

# 工具安装和环境搭建

本项目所实现的工作流至少包含两个项目节点，可扩展至三个节点：

+ **GPT-Sovits**，Github开源项目，并且B站已有大量up主的整合包，这里不再赘述。
  - 参考链接: [几分钟学会使用GPT-SoVITS-TTS](https://www.bilibili.com/video/BV16VMHzaEzS/?spm_id_from=333.1387.homepage.video_card.click&vd_source=299b695e25c7c90ef9d7045a49e37ee4)
+ **webgal-tools**
  - 安装：
    * 解压`release.zip`，进入目录，点击`install.bat`，约几分钟就可安装完成。
  - 使用：
    * 点击`voice-ui.bat`可以启动web界面
      + 优点是图形化操作简单，并且有大量的提示信息。
      + 缺点是性能开销会更大。
    * 点击cli.bat可启动命令行界面
      + 优点是在各种editor中能很方便的通过终端使用。
+ **模型服务商**
  - 如果你需要在语音合成前进行翻译，动态模型配置，需要获得对应模型提供商的api_key和base_url
  - 常用的模型服务商：OpenAI,Ollama,Antropic，阿里云百炼等。
  - **考虑到大部分人懒得去找api_key，所以本整合包还提供了ollama_install.zip，点击其中的install.bat可以帮助你正确的本地部署Ollama服务**
  - **如果你懒得看下面的一堆字，那就在安装完成后，运行**`**ollama run glm4:9b --verbose**`**,会自动下载模型并开启对话测试。**
  - Ollama服务可下载一些被量化过的模型到本地，以便在个人电脑上运行
    * 需要了解的简单的运行命令
      + `ollama pull 模型名`，下载模型，国内可访问，如果你发现下载一段时间后速度越来越慢，请中断下载，并马上重新运行同样的下载命令，会逐渐恢复到原来的下载速度。
        - 如果有梯子，下载速度会快一些。
      + `ollama run 模型名`，运行模型，如果模型未下载则会自动下载。首次加载模型时（冷启动）要等一小会儿才能运行服务。
      + `ollama run 模型名 --verbose`，每次对话后，输出token统计信息。
      + `ollam rm 模型名`删除模型
      + 其它补充：一般来说，安装ollama后，会将ollama网络服务加入Windows Service，以在后台随时待机，这样你就不用每次都去手动打开ollama网络服务。
        - 如果你想要手动开启，可以手动点击安装目录的ollama.exe来启动
        - 如果你确实想要在控制台手动启动ollama网络服务，执行`ollama serve`
    * 如果你只是简单的翻译任务，`ollama pull gemma3:4b`足够了
    * 如果你需要使用动态配置，或者更好的上下文理解质量，`glm4:9b`可以(当然不是满血)，或者更轻量一些的`glm4:9b-chat-q3_K_S`
    * [Tags · glm4](https://ollama.com/library/glm4/tags)
    * 如果你还想要自己使用一些其它的模型，对于同一类模型，按照以下规则选型号
      + 优先看参数体量的大小（b）,尽量大，但是体积在自身设备承受范围内。
      + 大参数的模型被量化后能降低表示参数的位数，以适应低端设备。
      + 选择量化模型的简单规则：
        - q越小，运行越流畅，但是能力下降更多
        - it(int,整数)，fp(浮点数)，int比fp对设备要求更低，但是能力也是下降
        - _S < _M < _L（small,middle,large）
      + 其它
        - chat: 相对适应对话类任务
        - text: 相对适应文本类任务

# voice-ui

voice-ui是本项目的图形化操作界面，帮助用户快速熟悉工具的具体参数和操作方式。

安装工具后，点击`voice-ui.bat`即可运行，服务启动成功后会自动打开浏览器。

## 首页

我们的工作流是基于Webgal项目游戏项目来进行的，你需要先输入工作目录来创建工作区，历史工作区会保存在右侧历史目录中，以便于下次快速进入。

![](https://cdn.nlark.com/yuque/0/2025/png/44192272/1751979284353-ea9b9c09-b9bd-47b0-a4bf-a1de0f42f7d3.png)

为了演示，我们在webgal中创建了一个名为test的游戏项目，并进入到其中的game目录。

![](https://cdn.nlark.com/yuque/0/2025/png/44192272/1751979558125-f130d985-90cd-4627-8f58-2d02f21921fe.png)

复制目录的绝对路径，填入输入框，并点击添加工作区：

![](https://cdn.nlark.com/yuque/0/2025/png/44192272/1751979612225-9d0ef0e9-3544-402c-9bed-741a5bcc69b7.png)

添加成功！，现在你可以点击右上角的`返回首页`来切换工作区

![](https://cdn.nlark.com/yuque/0/2025/png/44192272/1751979879260-c7082f30-5aeb-4e5f-af8c-8ea8b6053045.png)

可以看到，工作区被保存了，你可以从这里快速进入，或者删除工作区

![](https://cdn.nlark.com/yuque/0/2025/png/44192272/1751979927033-b2c94d2e-59ef-44e5-858a-4b88bd43a296.png)

## 工作区

### 初始化

创建工作区后，首先需要你初始化项目配置。

![](https://cdn.nlark.com/yuque/0/2025/png/44192272/1751980002807-f18f90e1-be03-48a0-b543-6905d87370e5.png)

当项目下存在配置时，为了避免你多次重复初始化，除非你勾选强制初始化来覆盖配置文件，否则你不能再次点击初始化按钮。

![](https://cdn.nlark.com/yuque/0/2025/png/44192272/1751980607112-2ceec16f-5fb1-4400-9bf8-89adbc66e6d5.png)

![](https://cdn.nlark.com/yuque/0/2025/png/44192272/1751980619462-871879bc-dcc3-4db2-897a-54e1e1d628c2.png)

#### 自定义初始化模板

![](https://cdn.nlark.com/yuque/0/2025/png/44192272/1751980778044-cb748833-853d-4cc1-bcc0-1a321411d92e.png)

![](https://cdn.nlark.com/yuque/0/2025/png/44192272/1751980795601-6aa3d664-fade-482a-a95b-877c37072435.png)

![](https://cdn.nlark.com/yuque/0/2025/png/44192272/1751980809595-b105c082-6a59-4590-b01c-29906775f7e0.png)

### 基本配置

![](https://cdn.nlark.com/yuque/0/2025/png/44192272/1751981926038-bd5eb384-ebe9-4873-9479-0dbe82f59f38.png)

+ 音量：即webgal脚本的volume参数值，用于统一全局角色语音大小
+ 服务地址：GPT-SoVITS的默认的TTS服务地址，在开始合成之前你需要确认GPT-SoVITS的TTS推理已经开启
+ 模型版本：v1-v4
+ 最大翻译并发：如果你是本地部署的Ollama服务，默认的1就可以了，如果你使用其它的云端模型服务，需要参照服务商的文档查看允许的cpm(call per minute)

### 翻译配置

![](https://cdn.nlark.com/yuque/0/2025/png/44192272/1751982203672-68a0fe06-fbe1-4bf9-a9bf-9d08e37d317c.png)

可选择开启或者关闭翻译配置

+ 模型服务商
+ 模型服务baseurl，本地ollama就保持默认即可
+ 模型名：gemma3:4b可担任最基础的翻译质量，glm4:9b-chat-q3-K_S以上可保证动态配置的正确输出
+ apikey，本地ollama不需要填写
+ 上下文宽度：在翻译对话时，我们会提取对话附件的上下文来帮助模型进行一定的推理
+ 模型温度：0-1.0，温度越大，输出越随机，0.3是一个对大多数模型来说较稳定的参数
+ 最大输出token：限制输出长度，一般来说，没有一个webgal角色的一句对话会有上百字吧..，512一般足够
+ 全局提示词：常用于指导人物昵称、人物关系的说明，以提升翻译质量

### 角色配置

![](https://cdn.nlark.com/yuque/0/2025/png/44192272/1751983349307-721b63a8-f9fe-4d87-9c93-2dadb7f0f585.png)

![](https://cdn.nlark.com/yuque/0/2025/png/44192272/1751983375970-0b75f7de-f9de-44f0-9700-03e327db1c8e.png)

角色的配置几乎和gpt-sovits的tts服务页面的参数配置相似，但是额外增加了：、

+ 角色提示词，以进一步优化角色对话翻译质量，同时避免全局上下文导致输入token臃肿的问题。
+ 情绪识别（动态模型、参考音频装配），要求gpt,sovits,ref_audio的值指向资源目录，而不是具体的模型文件或者音频。稍后会详细介绍。
+ 不开启情绪识别的话，生成速度会更高，适合`海玲``若叶睦`这种声线基本没有情绪波动的角色配音。

角色模型的扫描深度相比gpt-sovits更深入，支持多层文件夹嵌套，以助于语义化。

![](https://cdn.nlark.com/yuque/0/2025/png/44192272/1751983606392-b1b8697b-5d6c-4b58-859b-65636b167a97.png)

对于静态配置，你可以上传音频，文件，并且上传后，我们将默认将音频文件名自动填入参考文本。

### 解析脚本并开始工作流

确认配置正常后，你可以选择目标脚本，并开始语音合成工作流，工作流日志的详细输出在cmd控制台。

![](https://cdn.nlark.com/yuque/0/2025/png/44192272/1751989429099-afb1320d-fccc-4ba3-aefe-735cbcdf2555.png)

**请确保开始前，GPT-SoVITS服务已开启。**

**如果你启用了翻译/动态模型配置，还需要保证Ollama服务正常。**

作者的配置是RTX 4060 laptop ,8G显存，glm4:9b，gpt-sovits-v2pp，16G内存，能流畅运行静态模型配置服务，正常运行动态模型配置。

# （可了解）使用软链接集中管理模型

由于GPT-SoVITS和本工具都需要访问模型文件。Windows系统提供了软链接功能，可以让你在不同位置引用同一个文件或目录，非常适合对于模型文件和参考音频按照角色分类的的集中管理。

## Windows下创建软链接

在Windows中，可以使用`mklink`命令创建软链接。这个命令需要在命令提示符(cmd)中执行：

```cmd
# 创建目录软链接的语法
mklink /D 链接路径 目标路径

# 示例：将模型文件集中存放在D盘，并在GPT-SoVITS目录中创建链接
mklink /D "D:\GPT-SoVITS\GPT_weights_v2ProPlus\mygo-mujica" "D:\AI_Models\models_and_audio"
mklink /D "D:\GPT-SoVITS\SoVITS_weights_v2ProPlus\mygo-mujica" "D:\AI_Models\models_and_audio"
```

## 软链接的优势

1. **节省磁盘空间**：模型文件只需保存一份
2. **便于管理**：可以在一个集中的位置管理所有模型
3. **简化配置**：无需在多个地方修改路径

## 推荐的模型管理结构

### 方案一：按模型类型分类

```
D:\AI_Models\                           # 集中存放所有AI模型的根目录
  ├─ GPT_weights\                       # GPT模型集合
  │   ├─ 角色1\                         # 按角色分类
  │   │   ├─ 角色1_happy.ckpt
  │   │   └─ 角色1_sad.ckpt
  │   └─ 角色2\
  │       ├─ 角色2_happy.ckpt
  │       └─ 角色2_angry.ckpt
  ├─ SoVITS_weights\                    # SoVITS模型集合
  │   ├─ 角色1\
  │   │   ├─ 角色1_happy.pth
  │   │   └─ 角色1_sad.pth
  │   └─ 角色2\
  │       ├─ 角色2_happy.pth
  │       └─ 角色2_angry.pth
  └─ ref_audio\                         # 参考音频集合
      ├─ 角色1\
      │   ├─ happy\
      │   │   └─ 示例音频.wav
      │   └─ sad\
      │       └─ 示例音频.wav
      └─ 角色2\
          ├─ happy\
          │   └─ 示例音频.wav
          └─ angry\
              └─ 示例音频.wav

D:\GPT-SoVITS\                          # GPT-SoVITS安装目录
  ├─ GPT_weights -> D:\AI_Models\GPT_weights     # 软链接
  └─ SoVITS_weights -> D:\AI_Models\SoVITS_weights   # 软链接
```

### 方案二：按角色集中管理

```
D:\AI_Models\                           # 集中存放所有AI模型的根目录
  ├─ 角色1\                             # 按角色分类
  │   │─ 角色1_happy.ckpt
  │   │─ 角色1_sad.ckpt
  │   │─ 角色1_happy.pth
  │   │─ 角色1_sad.pth
  │   ├─ happy\
  │   │   └─ 示例音频.wav
  │   └─ sad\
  │       └─ 示例音频.wav
  └─ 角色2\                             # 另一个角色
      │─ 角色2_happy.ckpt
      │─ 角色2_angry.ckpt
      │─ 角色2_happy.pth
      │─ 角色2_angry.pth
      ├─ happy\
      │   └─ 示例音频.wav
      └─ angry\
          └─ 示例音频.wav

D:\GPT-SoVITS\                          # GPT-SoVITS安装目录
  ├─ GPT_weights_v2ProPlus\mygo-mujica -> D:\AI_Models\角色1\gpt     # 软链接
  └─ SoVITS_weights_v2ProPlus\mygo-mujica -> D:\AI_Models\角色1\sovits   # 软链接
```

这样设置后，你可以根据自己的偏好选择合适的组织方式。方案一按模型类型分类更符合GPT-SoVITS的默认目录结构，方案二则让每个角色的所有资源更集中，便于管理。

# 开始第一个工作流："静态角色配置"

静态角色配置是最基础的配置方式，适合声线变化不大的角色，或者你希望快速生成语音的场景。

## 配置步骤

1. 在角色配置页面，添加一个新角色
2. 填写角色名称（与WebGAL脚本中的名称一致）
3. 关闭"情绪识别"开关（auto设为false）
4. 选择GPT模型文件和SoVITS模型文件
5. 上传参考音频文件，或者指定已有的参考音频路径
6. 填写参考文本（如果上传了音频文件，会自动填入文件名作为参考文本）
7. 如果需要翻译，填写"翻译目标语言"和"角色提示词"
8. 根据需要调整推理配置参数

## 静态配置的优势

- 处理速度快：无需额外的情感分析步骤
- 稳定可控：每次生成的语音风格相对动态配置来说更一致
- 资源占用低：适合配置较低的电脑

## 示例配置

```json
{
  "character_name": "祥子",
  "auto": false,
  "gpt": "GPT_weights_v2ProPlus/mygo-mujica/丰川祥子（Sakiko）/丰川祥子_neutral_v2pp.ckpt", // 填写你的gpt路径（相对于gpt-sovits项目根目录的路径）
  "sovits": "SoVITS_weights_v2ProPlus/mygo-mujica/丰川祥子（Sakiko）/丰川祥子_neutral_v2pp.pth", // 填写你的sovits路径（相对于gpt-sovits项目根目录的路径）
  "ref_audio": "D:/AIVoice/W_A/丰川祥子（Sakiko）/neutral/あなたと空を見上げるのは、いつも夏でしたわね.wav", // 填写你的参考音频路径（绝对路径）
  "ref_text": "あなたと空を見上げるのは、いつも夏でしたわね", // 参考音频的参考文本
  "prompt": "【口吻】高傲威严的大小姐腔调，善用命令句式（〜なさい/〜ですわ），语速中等偏快，强调重音明显。日文自称'私（わたくし）'，他称'諸君'。代表句尾：'ですわ'、'かしら'", // 自定义角色提示词
  "translate_to": "日语", // 角色配音的语种
  "inferrence_config": {
    "prompt_language": "日文", // 参考音频的语种 
    "text_language": "日文", // 参考文本的语种
    "how_to_cut": "凑四句一切",
    "top_k": 15,
    "top_p": 1,
    "temperature": 1,
    "speed": 1,
    "sample_steps": 8,
    "if_sr": false,
    "pause_second": 0.5
  }
}
```

# 开始第二个工作流："动态角色配置"

动态角色配置可以根据对话内容自动选择相对更合适的情感模型和参考音频，让角色的语音表现更加丰富多样。

## 配置步骤

1. 在角色配置页面，添加一个新角色
2. 填写角色名称（与WebGAL脚本中的名称一致）
3. 开启"情绪识别"开关（auto设为true）
4. **关键步骤**：指定模型目录而非具体文件
   - GPT字段填写模型扫描目录路径
   - SoVITS字段填写模型扫描目录路径
   - ref_audio字段填写参考音频目录路径
5. 填写角色提示词，帮助AI更好地理解角色情感
6. 如果需要翻译，填写"翻译目标语言"
7. 根据需要调整推理配置参数

## 动态配置的优势

- 相对静态配置更自然的情感表达：根据对话内容自动匹配音色模型和参考音频
- 智能化处理：减少手动选择模型的工作量

## 示例配置

```json
{
  "character_name": "喵梦",
  "auto": true, // 开启动态情绪识别
  "gpt": "GPT_weights_v2ProPlus/mygo-mujica/祐天寺若麦（喵梦）（Nyamu）", // 填写你的gpt模型存放目录的相对路径
  "sovits": "SoVITS_weights_v2ProPlus/mygo-mujica/祐天寺若麦（喵梦）（Nyamu）",  // 填写你的sovits模型存放目录的相对路径
  "ref_audio": "D:/AIVoice/W_A/祐天寺若麦（喵梦）（Nyamu）", // 参考音频的存放路径，但是注意，我们会将音频文件的文件名作为参考文本来使用，起名时务必注意。
  "prompt": "【口吻】轻浮活泼的网络主播腔，句尾音调上扬快活。自称'にゃむ'，称呼他人用'〜ち'（例：むつち）。代表句式：'超ヤバいにゃ！'、'ファンサービスしよっか〜'",
  "translate_to": "日文",
  "inferrence_config": {
    "prompt_language": "日文",
    "text_language": "日文",
    "how_to_cut": "凑四句一切",
    "top_k": 15,
    "top_p": 1.0,
    "temperature": 1.0,
    "speed": 1,
    "sample_steps": 8,
    "if_sr": false,
    "pause_second": 0.2
  }
}
```

## 动态配置工作原理

1. 当开启动态配置后，系统会**递归扫描**指定的模型和音频目录(仅会提取需要的文件，例如，扫描gpt模型时仅会囊括.ckpt文件)
2. 分析当前对话内容的情感和语气
3. 从目录中选择最匹配的GPT模型、SoVITS模型和参考音频。（每一种情感的参考音频不用特别多，有几个就够了）
4. **需要确保选择每一组的GPT模型和SoVITS模型文件名是相同的，避免模型不兼容导致合成效果割裂**
5. 使用选定的模型和音频生成语音

# 语义化文件路径

为了让动态模型配置能够更准确地选择合适的模型和音频，推荐使用语义化的文件命名和目录结构。

## 推荐的目录结构

```
/存放目录/模型文件（文件名包含角色名称、情感类型）
/存放目录/音频情感类型/音频文件（文件名推荐你设置为音频对应参考文本，以便我们在选择音频时自动获取）
```

例如：

```
/GPT_weights_v2ProPlus/喵梦/
  ├─ 喵梦_happy_v2pp.ckpt
  ├─ 喵梦_生气_v2pp.ckpt
  ├─ 喵梦_sad_v2pp.ckpt
  └─ 喵梦_neutral_v2pp.ckpt

/SoVITS_weights_v2ProPlus/喵梦/
  ├─ 喵梦_happy_v2pp.pth
  ├─ 喵梦_生气_v2pp.pth
  ├─ 喵梦_sad_v2pp.pth
  └─ 喵梦_neutral_v2pp.pth

对于同一组模型，你需要将模型名设置为相同的（例如喵梦_happy_v2pp.pth和喵梦_happy_v2pp.ckpt）
因为为了压缩上下文，也为了避免模型不兼容，我们将按照模型名来分组，以便使用。

/参考音频/喵梦/
  ├─ 开心/
  │  ├─ 你好.wav
  │  └─ 我是喵梦.wav
  ├─ angry/
  │  ├─ 什么？.wav
  │  └─ 哈？.wav
  ├─ sad/
  │  ├─ 呜呜呜.wav
```

## 文件命名建议

1. 在文件名中包含情感关键词，如happy、angry、sad、neutral等
2. 保持GPT模型和SoVITS模型的文件名基础部分一致
3. 参考音频的文件名也可以包含情感关键词
4. 使用统一的命名规则，便于系统识别

## 情感关键词示例

- 积极情感：happy、excited、cheerful、joyful
- 消极情感：sad、depressed、gloomy、melancholy
- 愤怒情感：angry、furious、irritated、annoyed
- 中性情感：neutral、calm、normal、regular
- 其他情感：surprised、scared、confused、embarrassed

# 模型选择和优化

## GPT-SoVITS模型版本选择

本工具支持GPT-SoVITS的多个版本：

- v1：最早的版本，功能相对基础
- v2：改进版本，语音质量有所提升
- v2pp (v2 Pro Plus)：目前推荐版本，综合性能最佳
- v3/v4：新版本，支持更多高级特性

根据你的需求和设备性能选择合适的版本。一般来说，v2pp即可。

## 翻译模型选择

根据不同的需求场景，可以选择不同的翻译模型：

- 简单翻译任务：gemma3:4b、Phi3:mini等轻量级模型
- 动态配置和上下文理解：glm4:9b等中型模型
- 高质量翻译和复杂场景：glm4:14b、llama3:70b等大型模型，但是大部分个人笔记本电脑应该很难达到一个有效率的生成速度了，即便使用最狠的量化。

## 性能优化建议

1. **模型量化**：选择适当量化的模型可以在保证质量的同时降低资源占用
   - q4_K_M：中等质量，适合大多数场景
   - q3_K_S：更低资源占用，质量略有下降，一般再小于这个标准，那生成质量真的就很难说了
   - q6_K：更高质量，但资源占用更大

2. **并发设置**：
   - 本地Ollama服务建议设置max_translator=1
   - 云端服务可以根据API限制适当提高并发数

3. **参考音频优化**：
   - 选择清晰、无背景噪音的音频
   - 音频长度建议在5-10秒之间
   - 确保音频内容与参考文本一致

4. **推理参数调整**：
   - top_k和top_p：值越大，生成结果越多样但可能不稳定
   - temperature：值越高，输出越随机；值越低，输出越确定
   - speed：调整语速，一般1.0为正常速度
   - sample_steps：步数越多，质量越高但速度越慢

# cli界面介绍

除了图形界面外，本工具还提供了命令行界面，适合在编辑器中直接使用或进行批处理操作。

## 启动方式

点击`cli.bat`

## 交互式模式

如果不带参数启动，cli将进入交互式模式：

1. 首先提示输入工作目录
2. 然后选择要执行的操作：
   - 初始化配置文件
   - 启动MCP服务器
   - 启动语音服务

## 命令行参数

也可以通过命令行参数直接指定操作，这使用于cursor等需要填写mcp配置的编辑器

```bash
# 启动MCP服务器，指定工作目录
pnpm @webgal-tools/cli --mcp D:/path/to/your/game

# 初始化配置（交互式）
pnpm @webgal-tools/cli
# 然后选择"初始化配置文件"选项
```

## 常用操作流程

1. **初始化项目**：
   ```bash
   # 输入工作目录
   # 选择"初始化配置文件"
   # 选择初始化类型和是否强制覆盖
   ```

2. **启动语音服务**：
   ```bash
   # 输入工作目录
   # 选择"启动语音服务"
   # 输入脚本文件路径和是否强制模式
   ```

3. **启动MCP服务器**：
   ```bash
   # 输入工作目录
   # 选择"启动MCP服务器"
   # 输入SSE服务器端口
   ```

## 与编辑器集成

cli工具可以方便地与各种编辑器集成，例如：

- **VSCode**：在终端中直接运行cli命令
- **WebStorm**：配置运行配置，快速启动服务
- **其他编辑器**：通过命令行或脚本集成

# 高级用法

## 自定义翻译提示词

全局提示词和角色提示词可以帮助提升翻译质量：

- **全局提示词**：适用于所有角色，通常包含人物关系、世界观等信息
- **角色提示词**：针对特定角色的语言风格、口头禅等特征

## 与WebGAL编辑器集成

本工具可以与WebGAL编辑器配合使用，实现一站式的游戏开发流程：

1. 在WebGAL编辑器中编写剧本
2. 使用本工具生成语音
3. 在WebGAL编辑器中预览和调整
4. 最终导出完整游戏

# 常见问题解答

## Q: 为什么我的语音生成速度很慢？
A: 可能的原因包括：1) GPU性能不足；2) 模型版本过重；3) 动态配置模式下情感分析耗时；4) 翻译服务响应慢。建议尝试使用更轻量的模型或关闭动态配置。

## Q: 如何提高翻译质量？
A: 提供更详细的全局提示词和角色提示词，使用更强大的翻译模型，适当调整模型温度和上下文宽度。

## Q: 生成的语音有杂音或不自然？
A: 检查参考音频质量，调整推理参数（如sample_steps增加到12-16），确保GPT和SoVITS模型匹配。

## Q: 如何备份我的配置？
A: 一般来说，每次生成语音和修改配置时，我们都会再工作目录下的.voice-backups和.voice-config-backups产生备份文件，以便你恢复到之前的工作状态。

感谢使用WebGAL工具集！如有更多问题，请访问我们的GitHub仓库或社区论坛获取支持，并提供详细的信息。
